{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"#test","title":"Test","text":""},{"location":"scrapy/","title":"Scrapy Tutorial","text":""},{"location":"scrapy/#creating-a-project","title":"Creating a project","text":"<p><code>scrapy startproject &lt;project name&gt;</code></p> <ul> <li><code>scrapy.cfg</code>: the project configuration file</li> <li><code>tutorial/</code>: the project\u2019s python module, you\u2019ll later import your code from here.</li> <li><code>tutorial/items.py</code>: the project\u2019s items file.</li> <li><code>tutorial/pipelines.py</code>: the project\u2019s pipelines file.</li> <li><code>tutorial/settings.py</code>: the project\u2019s settings file.</li> <li><code>tutorial/spiders/</code>: a directory where you\u2019ll later put your spiders.</li> </ul>"},{"location":"scrapy/#defining-our-item","title":"Defining our Item","text":"<pre><code>import scrapy\n\nclass DmozItem(scrapy.Item):\n    title = scrapy.Field()\n    link = scrapy.Field()\n    desc = scrapy.Field()\n</code></pre>"},{"location":"scrapy/#our-first-spider","title":"Our first Spider","text":"<ul> <li> <p><code>name</code>: identifies the Spider. It must be unique, that is, you can\u2019t set the same name for different Spiders.</p> </li> <li> <p><code>start_urls</code>: is a list of URLs where the Spider will begin to crawl from. So, the first pages downloaded will be those listed here. The subsequent URLs will be generated successively from data contained in the start URLs.</p> </li> <li> <p><code>parse()</code> is a method of the spider, which will be called with the downloaded <code>Response</code> object of each start URL. The response is passed to the method as the first and only argument.</p> <p>This method is responsible for parsing the response data and extracting scraped data (as scraped items) and more URLs to follow.</p> <p>The <code>parse()</code> method is in charge of processing the response and returning scraped data (as <code>Item</code> objects) and more URLs to follow (as <code>Request</code> objects).</p> </li> </ul> <pre><code>#demo_spider.py\n\nimport scrapy\n\nclass DmozSpider(scrapy.Spider):\n    name = \"dmoz\"\n    allowed_domains = [\"dmoz.org\"]\n    start_urls = [\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\"\n    ]\n\n    def parse(self, response):\n        filename = response.url.split(\"/\")[-2]\n        with open(filename, 'wb') as f:\n            f.write(response.body)\n</code></pre>"},{"location":"scrapy/#crawling","title":"Crawling","text":"<p><code>scrapy crawl dmoz</code></p>"},{"location":"recipes/recipes/","title":"Prefect Recipes","text":"<p>Prefect recipes are common, extensible examples for setting up Prefect in your execution environment with ready-made ingredients such as Dockerfiles, Terraform files, and GitHub Actions.</p> <p>Recipes are useful when you are looking for tutorials on how to deploy an agent, use event-driven flows, set up unit testing, and more.</p> <p>The following are Prefect recipes specific to Prefect 2. You can find a full repository of recipes at https://github.com/PrefectHQ/prefect-recipes and additional recipes at Prefect Discourse.</p>","tags":["recipes","best practices","examples"]},{"location":"recipes/recipes/#recipe-catalog","title":"Recipe catalog","text":"","tags":["recipes","best practices","examples"]},{"location":"recipes/recipes/#contributing-recipes","title":"Contributing recipes","text":"<p>We're always looking for new recipe contributions! See the Prefect Recipes repository for details on how you can add your Prefect recipe, share best practices with fellow Prefect users, and earn some swag. </p> <p>Prefect recipes provide a vital cookbook where users can find helpful code examples and, when appropriate, common steps for specific Prefect use cases.</p> <p>We love recipes from anyone who has example code that another Prefect user can benefit from (e.g. a Prefect flow that loads data into Snowflake).</p> <p>Have a blog post, Discourse article, or tutorial you\u2019d like to share as a recipe? All submissions are welcome. Clone the prefect-recipes repo, create a branch, add a link to your recipe to the README, and submit a PR. Have more questions? Read on.</p>","tags":["recipes","best practices","examples"]},{"location":"recipes/recipes/#what-is-a-recipe","title":"What is a recipe?","text":"<p>A Prefect recipe is like a cookbook recipe: it tells you what you need \u2014 the ingredients \u2014 and some basic steps, but assumes you can put the pieces together. Think of the Hello Fresh meal experience, but for dataflows.</p> <p>A tutorial, on the other hand, is Julia Child holding your hand through the entire cooking process: explaining each ingredient and procedure, demonstrating best practices, pointing out potential problems, and generally making sure you can\u2019t stray from the happy path to a delicious meal.</p> <p>We love Julia, and we love tutorials. But we don\u2019t expect that a Prefect recipe should handhold users through every step and possible contingency of a solution. A recipe can start from an expectation of more expertise and problem-solving ability on the part of the reader.</p> <p>To see an example of a high quality recipe, check out Serverless with AWS Chalice. This recipe includes all of the elements we like to see.</p>","tags":["recipes","best practices","examples"]},{"location":"recipes/recipes/#steps-to-add-your-recipe","title":"Steps to add your recipe","text":"<p>Here\u2019s our guide to creating a recipe:</p> <pre><code># Clone the repository\ngit clone git@github.com:PrefectHQ/prefect-recipes.git\ncd prefect-recipes\n\n# Create and checkout a new branch\ngit checkout -b new_recipe_branch_name\n</code></pre> <ol> <li>Add your recipe. Your code may simply be a copy/paste of a single Python file or an entire folder. Unsure of where to add your file or folder? Just add under the <code>flows-advanced/</code> folder. A Prefect Recipes maintainer will help you find the best place for your recipe. Just want to direct others to a project you made, whether it be a repo or a blogpost? Simply link to it in the Prefect Recipes README!</li> <li>(Optional) Write a README.</li> <li>Include a dependencies file, if applicable.</li> <li>Push your code and make a PR to the repository.</li> </ol> <p>That\u2019s it! </p>","tags":["recipes","best practices","examples"]},{"location":"recipes/recipes/#what-makes-a-good-recipe","title":"What makes a good recipe?","text":"<p>Every recipe is useful, as other Prefect users can adapt the recipe to their needs. Particularly good ones help a Prefect user bake a great dataflow solution! Take a look at the prefect-recipes repo to see some examples.</p>","tags":["recipes","best practices","examples"]},{"location":"recipes/recipes/#what-are-the-common-ingredients-of-a-good-recipe","title":"What are the common ingredients of a good recipe?","text":"<ul> <li>Easy to understand: Can a user easily follow your recipe? Would a README or code comments help? A simple explanation providing context on how to use the example code is useful, but not required. A good README can set a recipe apart, so we have some additional suggestions for README files below.</li> <li>Code and more: Sometimes a use case is best represented in Python code or shell scripts. Sometimes a configuration file is the most important artifact \u2014 think of a Dockerfile or Terraform file for configuring infrastructure.</li> <li>All-inclusive: Share as much code as you can. Even boilerplate code like Dockerfiles or Terraform or Helm files are useful. Just don\u2019t share company secrets or IP.</li> <li>Specific: Don't worry about generalizing your code, aside from removing anything internal/secret! Other users will extrapolate their own unique solutions from your example.</li> </ul>","tags":["recipes","best practices","examples"]},{"location":"recipes/recipes/#what-are-some-tips-for-a-good-recipe-readme","title":"What are some tips for a good recipe README?","text":"<p>A thoughtful README can take a recipe from good to great. Here are some best practices that we\u2019ve found make for a great recipe README:</p> <ul> <li>Provide a brief explanation of what your recipe demonstrates. This helps users determine quickly whether the recipe is relevant to their needs or answers their questions.</li> <li>List which files are included and what each is meant to do. Each explanation can contain only a few words.</li> <li>Describe any dependencies and prerequisites (in addition to any dependencies you include in a requirements file). This includes both libraries or modules and any services your recipes depends on.</li> <li>If steps are involved or there\u2019s an order to do things, a simple list of steps is helpful.</li> <li>Bonus: troubleshooting steps you encountered to get here or tips where other users might get tripped up.</li> </ul>","tags":["recipes","best practices","examples"]},{"location":"recipes/recipes/#next-steps","title":"Next steps","text":"<p>We hope you\u2019ll feel comfortable sharing your Prefect solutions as recipes in the prefect-recipes repo. Collaboration and knowledge sharing are defining attributes of our Prefect Community! </p> <p>Have questions about sharing or using recipes? Reach out on our active Prefect Slack Community!</p> <p>Happy engineering!</p>","tags":["recipes","best practices","examples"]},{"location":"tutorial/","title":"Tutorial Overview","text":"<p>These tutorials provide examples of Prefect core concepts and step-by-step instructions on how to use them. For specific examples of how to perform more advanced tasks, check out our guides.</p> <p>If you have used Prefect 1 (\"Prefect Core\") and are familiar with Prefect workflows, we still recommend reading through these first steps, particularly Run a flow within a flow. Prefect 2 flows and subflows offer significant new functionality.</p>","tags":["tutorial","getting started","basics","tasks","flows","subflows"]},{"location":"tutorial/#prerequisites","title":"Prerequisites","text":"<p>Before you start, install Prefect:</p> <pre><code>pip install -U prefect\n</code></pre> <p>See the install guide for more detailed instructions.</p>","tags":["tutorial","getting started","basics","tasks","flows","subflows"]},{"location":"tutorial/#tutorials","title":"Tutorials","text":"<p>If you've never used Prefect before, let's start by exploring the core concepts:</p> <ol> <li>Flows &amp; tasks - the core elements of Prefect.</li> <li>Configuration - enhance your flows and tasks with parameters, retries, caching, and task runners.</li> <li>Execution - configure how your flows and tasks run.</li> <li>Orchestration - the components of Prefect that enable coordination and orchestration of your flow and task runs.</li> <li>Deployments - enable remote flow run execution.</li> <li>Storage &amp; Infrastructure - specify where your flow code is stored and how to configure the execution environment.</li> </ol>","tags":["tutorial","getting started","basics","tasks","flows","subflows"]},{"location":"tutorial/deployments/","title":"Flow deployments","text":"<p>Leading up to this section, you've been able to explore Prefect capabilities like flows, tasks, retries, caching, and so on. But so far, you've run flows as scripts.</p> <p>Deployments take your flows to the next level: adding the information needed for scheduling flow runs or triggering a flow run via an API call. Deployments elevate workflows from functions that you call manually to API-managed entities. Deployments also enable remote flow run execution.</p> <p>Run deployments with Prefect Cloud</p> <p>The same steps demonstrated in this tutorial work to apply deployments and create flow runs from them with Prefect Cloud. </p> <p>See the Prefect Cloud Quickstart for step-by-step instructions to log into Prefect Cloud, create a workspace, and configure your local environment to use Prefect Cloud as the API backend. Then run through this tutorial again, using Prefect Cloud instead of a local Prefect server.</p> <p>Projects: An improved experience</p> <p>Prefect Deployments are getting even easier with the introduction of Projects, currently in beta.</p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#components-of-a-deployment","title":"Components of a deployment","text":"<p>You need just a few ingredients to turn a flow definition into a deployment:</p> <ul> <li>A Python script that contains a function decorated with <code>@flow</code></li> </ul> <p>That's it. To create flow runs based on the deployment, you need a few more pieces:</p> <ul> <li>Prefect orchestration engine, either Prefect Cloud or a local Prefect server started with <code>prefect server start</code>.</li> <li>An agent and work pool.</li> </ul> <p>These all come with Prefect. You just have to configure them and set them to work. You'll see how to configure each component during this tutorial.</p> <p>Optionally, you can configure storage for packaging and saving your flow code and dependencies. </p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#setting-up","title":"Setting up","text":"<p>First, create a new folder that will contain all of the files and dependencies needed by your flow deployment. This is a best practice for developing and deploying flows.</p> <pre><code>$ mkdir prefect-tutorial\n$ cd prefect-tutorial\n</code></pre> <p>You may organize your flow scripts and dependencies in any way that suits your team's needs and standards. For this tutorial, we'll keep files within this directory.</p> <p>In order to demonstrate some of the benefits of Prefect deployments, let's add two additional files to our folder:</p> <pre><code>$ echo '{\"some-piece-of-config\": 100}' &gt; config.json\n$ echo 'AN_IMPORTED_MESSAGE = \"Hello from another file\"' &gt; utilities.py\n</code></pre>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#from-flow-to-deployment","title":"From flow to deployment","text":"<p>As noted earlier, the first ingredient of a deployment is a flow script. You've seen a few of these already, and perhaps have written a few, if you've been following the tutorials. </p> <p>Let's start with a simple example that captures many aspects of a standard project:</p> <ul> <li>Utility files that you import from to keep your code clean.</li> <li>Parameterized runs with a basic CLI interface.</li> <li>Logging.</li> </ul> <p>This flow contains a single flow function <code>log_flow()</code>, and a single task <code>log_task</code> that logs messages based on a parameter input, your installed Prefect version, and an imported message from another file in your project:</p> <pre><code>import sys\nimport prefect\nfrom prefect import flow, task, get_run_logger\nfrom utilities import AN_IMPORTED_MESSAGE\n\n\n@task\ndef log_task(name):\n    logger = get_run_logger()\n    logger.info(\"Hello %s!\", name)\n    logger.info(\"Prefect Version = %s \ud83d\ude80\", prefect.__version__)\n    logger.debug(AN_IMPORTED_MESSAGE)\n\n\n@flow()\ndef log_flow(name: str):\n    log_task(name)\n\n\nif __name__ == \"__main__\":\n    name = sys.argv[1]\n    log_flow(name)\n</code></pre> <p>Save this in a file <code>log_flow.py</code> and run it as a Python script: <code>python log_flow.py Marvin</code>. You'll see output like this:</p> <pre><code>$ python log_flow.py Marvin\n22:00:16.419 | INFO    | prefect.engine - Created flow run 'vehement-eagle' for flow 'log-flow'\n22:00:16.570 | INFO    | Flow run 'vehement-eagle' - Created task run 'log_task-82fbd1c0-0' for task 'log_task'\n22:00:16.570 | INFO    | Flow run 'vehement-eagle' - Executing 'log_task-82fbd1c0-0' immediately...\n22:00:16.599 | INFO    | Task run 'log_task-82fbd1c0-0' - Hello Marvin!\n22:00:16.600 | INFO    | Task run 'log_task-82fbd1c0-0' - Prefect Version = 2.3.1 \ud83d\ude80\n22:00:16.626 | INFO    | Task run 'log_task-82fbd1c0-0' - Finished in state Completed()\n22:00:16.659 | INFO    | Flow run 'vehement-eagle' - Finished in state Completed('All states completed.')\n</code></pre> <p>Like previous flow examples, this is still a script that you have to run locally. </p> <p>In this tutorial, you'll use this flow script (and its supporting files!) to create a deployment on the Prefect server. With a deployment, you can trigger ad-hoc parametrized flow runs via the UI or an API call. You could also schedule automatic flow runs that run anywhere you can run a Prefect agent, including on remote infrastructure. </p> <p>You'll create the deployment for this flow by doing the following: </p> <ul> <li>Configure deployment settings via one of Prefect's interfaces (CLI or Python).</li> <li>Optionally copy the relevant flow files to a specified storage location from which it can be retrieved for flow runs </li> <li>Apply the deployment settings to create a deployment on the Prefect server</li> <li>Inspect the deployment with the Prefect CLI and Prefect UI</li> <li>Start an ad hoc flow run based on the deployment</li> </ul>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#deployment-creation-with-the-prefect-cli","title":"Deployment creation with the Prefect CLI","text":"<p>To create a deployment from an existing flow script using the CLI, there are just a few steps:</p> <ol> <li>Use the <code>prefect deployment build</code> Prefect CLI command to create a deployment definition YAML file. By default this step also uploads your flow script and any supporting files to storage, if you've specified storage for the deployment.</li> <li>Optionally, before applying, you can edit the deployment YAML file to include additional settings that are not easily specified via CLI flags. </li> <li>Use the <code>prefect deployment apply</code> Prefect CLI command to create the deployment with the Prefect server based on the settings in the deployment YAML file.</li> </ol>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#build-a-deployment-definition","title":"Build a deployment definition","text":"<p>All you need for the first step, building the deployment artifacts, is:</p> <ul> <li>The path and filename of the flow script.</li> <li>The name of the flow function that is the entrypoint to the flow.</li> <li>A name for the deployment.</li> </ul> <p>Entrypoint</p> <p>What do we mean by the \"entrypoint\" function?</p> <p>A flow script file may contain definitions for multiple flow (<code>@flow</code>) and task (<code>@task</code>) functions. The entrypoint is the flow function that is called to begin the workflow, and other task and flow functions may be called from within the entrypoint flow.  </p> <p>You can provide additional settings \u2014 we'll demonstrate that in a future step \u2014 but this is the minimum required information to create a deployment.</p> <p>To build deployment files for <code>log_flow.py</code>, use the following command:</p> <pre><code>$ prefect deployment build ./log_flow.py:log_flow -n log-simple -q test\n</code></pre> <p>What did we do here? Let's break down the command:</p> <ul> <li><code>prefect deployment build</code> is the Prefect CLI command that enables you to prepare the settings for a deployment.</li> <li><code>./log_flow.py:log_flow</code> specifies the location of the flow script file and the name of the entrypoint flow function, separated by a colon.</li> <li><code>-n log-simple</code> specifies a name for the deployment.</li> <li><code>-q test</code> specifies a work pool for the deployment. work pools direct scheduled runs to agents.</li> </ul> <p>You can pass other option flags. For example, you may specify multiple tags by providing a <code>-t tag</code> parameter for each tag you want applied to the deployment. Options are described in the Deployments documentation or via the <code>prefect deployment build --help</code> command.</p> <p>What happens when you run <code>prefect deployment build</code>? </p> <pre><code>$ prefect deployment build ./log_flow.py:log_flow -n log-simple -q test\nFound flow 'log-flow'\nDefault '.prefectignore' file written to\n/Users/terry/prefect-tutorial/.prefectignore\nDeployment storage None does not have upload capabilities; no files uploaded.  Pass --skip-upload to suppress this warning.\nDeployment YAML created at\n'/Users/terry/prefect-tutorial/log_flow-deployment.yaml'.\n</code></pre> <p>First, the <code>prefect deployment build</code> command checks that a valid flow script and entrypoint flow function exist before continuing.</p> <p>Next, since we don't have one already in the folder, the command writes a <code>.prefectignore</code> file to the working directory where you ran the <code>build</code> command. </p> <p>If we had specified remote storage for the deployment, the command would have attempted to upload files to the storage location. Since we did not specify storage, the deployment references the local files. We'll cover differences between using local storage and configuring a remote storage block in a later step.</p> <p>Finally, it writes a <code>log_flow-deployment.yaml</code> file, which contains details about the deployment for this flow.</p> <p>You can list the contents of the folder to see what we have at this step in the deployment process:</p> <pre><code>~/prefect-tutorial $ ls -a\n.               .prefectignore      config.json                 log_flow.py\n..              __pycache__         log_flow-deployment.yaml    utilities.py\n</code></pre> <p>Ignoring files with <code>.prefectignore</code></p> <p>By default, <code>prefect deployment build</code> automatically uploads your flow script and any supporting files in the present working directory to storage (if you've specified remote storage for the deployment).</p> <p>To exclude files from being uploaded, you can create a <code>.prefectignore</code> file. <code>.prefectignore</code> enables you to specify files that should be ignored by the deployment creation process. The syntax follows <code>.gitignore</code> patterns.</p> <p><code>.prefectignore</code> is preconfigured with common artifacts from Python, environment managers, operating systems, and other applications that you probably don't want included in flows uploaded to storage. </p> <p>It's also a good flow development practice to store flow files and their dependencies in a folder structure that helps ensure only the files needed to execute flow runs are uploaded to storage.</p> <p>In our example, we might add a line to <code>.prefectignore</code> for <code>config.json</code> as it is an unused file.</p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#configure-the-deployment","title":"Configure the deployment","text":"<p>Note that the flow requires a <code>name</code> parameter, but we didn't specify one when building the <code>deployment.yaml</code> file. To make sure flow runs based on this deployment have a default <code>name</code> parameter, we'll add one to the deployment definition.  Additionally, one of our logs is a <code>DEBUG</code> level log \u2014 to ensure that log is emitted, we will specify a custom environment variable.</p> <p>Open the <code>log_flow-deployment.yaml</code> file and edit the parameters to include a default as <code>parameters: {'name': 'Marvin'}</code> and the <code>infra_overrides</code> to include the relevant environment variable (note that both JSON and nested key/value pairs work here):</p> <pre><code>###\n### A complete description of a Prefect Deployment for flow 'log-flow'\n###\nname: log-simple\ndescription: null\nversion: 450637a8874a5dd3a81039a89e90c915\n# The work pool that will handle this deployment's runs\nwork_queue_name: test\nwork_pool_name: null\ntags: []\nparameters: {'name': 'Marvin'}\nschedule: null\ninfra_overrides:\nenv:\nPREFECT_LOGGING_LEVEL: DEBUG\ninfrastructure:\ntype: process\nenv: {}\nlabels: {}\nname: null\ncommand:\n- python\n- -m\n- prefect.engine\nstream_output: true\n\n###\n### DO NOT EDIT BELOW THIS LINE\n###\nflow_name: log-flow\nmanifest_path: null\nstorage: null\npath: /Users/terry/test/dplytest/prefect-tutorial\nentrypoint: log_flow.py:log_flow\nparameter_openapi_schema:\ntitle: Parameters\ntype: object\nproperties:\nname:\ntitle: name\ntype: string\nrequired:\n- name\ndefinitions: null\n</code></pre> <p>Note that the YAML configuration includes the ability to add a description, a default work pool, tags, a schedule, and more. </p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#apply-the-deployment","title":"Apply the deployment","text":"<p>To review, we have four files that make up the artifacts for this particular deployment (there could be more if we had supporting libraries or modules, configuration, and so on).</p> <ul> <li>The flow code in <code>log_flow.py</code></li> <li>The supporting code in <code>utilities.py</code></li> <li>The ignore file <code>.prefectignore</code></li> <li>The deployment definition in <code>log_flow-deployment.yaml</code></li> </ul> <p>Now we can apply the settings in <code>log_flow-deployment.yaml</code> to create the deployment object on the Prefect server API \u2014 or on a Prefect Cloud workspace if you had configured the Prefect Cloud API as your backend. </p> <p>Use the <code>prefect deployment apply</code> command to create the deployment on the Prefect server, specifying the name of the <code>log_flow-deployment.yaml</code> file.</p> <pre><code>$ prefect deployment apply log_flow-deployment.yaml\nSuccessfully loaded 'log-simple'\nDeployment 'log-flow/log-simple' successfully created with id\n'517fd294-2bd3-4738-9515-0c68092ce35d'.\n</code></pre> <p>You can now use the Prefect CLI to create a flow run for this deployment and run it with an agent that pulls work from the 'test' work pool:</p> <pre><code>$ prefect deployment run 'log-flow/log-simple'\n$ prefect agent start -q 'test'\n</code></pre> <p>Now your deployment has been created by the Prefect API and is ready to create future <code>log_flow</code> flow runs through the API or the scheduler.</p> <p>To demonstrate that your deployment exists, list all of the current deployments:</p> <pre><code>$ prefect deployment ls\n                                Deployments\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name                                \u2503 ID                                   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 hello-flow/example-deployment       \u2502 60a6911e-1125-4a33-b37f-3ba16b86837d \u2502\n\u2502 leonardo_dicapriflow/leo-deployment \u2502 3d2f55a2-46df-4857-ab6f-6cc80ce9cf9c \u2502\n\u2502 log-flow/log-simple                 \u2502 517fd294-2bd3-4738-9515-0c68092ce35d \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Use <code>prefect deployment inspect</code> to display details for a specific deployment.</p> <pre><code>$ prefect deployment inspect log-flow/log-simple\n{\n'id': '517fd294-2bd3-4738-9515-0c68092ce35d',\n    'created': '2022-08-22T20:06:54.719808+00:00',\n    'updated': '2022-08-22T20:06:54.717511+00:00',\n    'name': 'log-simple',\n    'version': '450637a8874a5dd3a81039a89e90c915',\n    'description': None,\n    'flow_id': 'da22db55-0a66-4f2a-ae5f-e0b898529a8f',\n    'schedule': None,\n    'is_schedule_active': True,\n    'infra_overrides': {'env': {'PREFECT_LOGGING_LEVEL': 'DEBUG'}},\n    'parameters': {'name': 'Marvin'},\n    'tags': [],\n    'work_queue_name': 'test',\n    'parameter_openapi_schema': {\n'title': 'Parameters',\n        'type': 'object',\n        'properties': {'name': {'title': 'name', 'type': 'string'}},\n        'required': ['name']\n},\n    'path': '/Users/terry/test/dplytest/prefect-tutorial',\n    'entrypoint': 'log_flow.py:log_flow',\n    'manifest_path': None,\n    'storage_document_id': None,\n    'infrastructure_document_id': '219341e5-0edb-474e-9df4-6c92122e56ce',\n    'infrastructure': {\n'type': 'process',\n        'env': {},\n        'labels': {},\n        'name': None,\n        'command': ['python', '-m', 'prefect.engine'],\n        'stream_output': True\n    }\n}\n</code></pre> <p>Customize this workflow to your needs</p> <p>You may not want Prefect to automatically upload your files in the build step, or you may want to do everything in one single CLI command. Whatever your preference, the Prefect CLI is highly customizable:</p> <ul> <li><code>prefect deployment build</code> accepts a <code>--skip-upload</code> flag that avoids automatic file uploads</li> <li><code>prefect deployment apply</code> accepts an <code>--upload</code> flag that performs the file upload in the apply step</li> <li><code>prefect deployment build</code> accepts an <code>--apply</code> flag that also performs the apply step</li> </ul>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#deployment-creation-with-python","title":"Deployment creation with Python","text":"<p>We can perform all of the same actions above with Python as our interface instead of the CLI \u2014 which interface to use is ultimately a matter of preference.</p> <p>Here we mirror the steps taken above with a new Python file saved as <code>deployment.py</code> in the root of our project directory:</p> <pre><code># deployment.py\n\nfrom log_flow import log_flow\nfrom prefect.deployments import Deployment\n\ndeployment = Deployment.build_from_flow(\n    flow=log_flow,\n    name=\"log-simple\",\n    parameters={\"name\": \"Marvin\"},\n    infra_overrides={\"env\": {\"PREFECT_LOGGING_LEVEL\": \"DEBUG\"}},\n    work_queue_name=\"test\",\n)\n\nif __name__ == \"__main__\":\n    deployment.apply()\n</code></pre> <p>All of the same configuration options apply here as well: you can skip automatic file uploads, apply and build in one step, etc.</p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#run-a-prefect-server","title":"Run a Prefect server","text":"<p>For the remainder of this tutorial, you'll use a local Prefect server. Open another terminal session and start the Prefect server with the <code>prefect server start</code> CLI command:</p> <pre><code>$ prefect server start\n\n ___ ___ ___ ___ ___ ___ _____ | _ \\ _ \\ __| __| __/ __|_   _|\n|  _/   / _|| _|| _| (__  | |\n|_| |_|_\\___|_| |___\\___| |_|\n\nConfigure Prefect to communicate with the server with:\n\n    prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api\n\nView the API reference documentation at http://127.0.0.1:4200/docs\n\nCheck out the dashboard at http://127.0.0.1:4200\n\n\n\nINFO:     Started server process [84832]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:4200 (Press CTRL+C to quit)\n</code></pre> <p>Set the <code>PREFECT_API_URL</code> for your server</p> <p>Note the message to set <code>PREFECT_API_URL</code>, configuring the URL of your Prefect server or Prefect Cloud makes sure that you're coordinating flows with the correct API instance.</p> <p>Go to your first terminal session and run this command to set the API URL to point to the Prefect server instance you just started:</p> <p> <pre><code>$ prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api\nSet variable 'PREFECT_API_URL' to 'http://127.0.0.1:4200/api'\nUpdated profile 'default'\n</code></pre> </p> <p>Use profiles to switch between 'PREFECT_API_URL' settings</p> <p>You can create configuration profiles to save commonly used settings. </p> <p> <pre><code># View current configuration\n$ prefect config view\nPREFECT_PROFILE='default'\nPREFECT_API_URL='http://127.0.0.1:4200/api' (from profile)\n\n# Create a \"local\" profile using these settings\n$ prefect profile create local --from default\n\nCreated profile with properties:\n    name - 'local'\nfrom name - default\n\nUse created profile for future, subsequent commands:\n    prefect profile use 'local'\n\nUse created profile temporarily for a single command:\n    prefect -p 'local' config view\n</code></pre> </p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#agents-and-work-pools","title":"Agents and work pools","text":"<p>As mentioned at the beginning of this tutorial, you still need two more items to run orchestrated deployments: an agent and a work pool. You'll set those up next.</p> <p>Agents and work pools are the mechanisms by which Prefect orchestrates deployment flow runs in remote execution environments.</p> <p>work pools let you organize flow runs for execution. Agents pick up work from one or more queues and execute the runs.</p> <p>In the Prefect UI, you can create a work pool by selecting the Work Pools page, then creating a new work pool. However, in our case you don't need to manually create a work pool because it was created automatically when you created your deployment. If you hadn't created your deployment yet, it would be created when you start your agent. </p> <p>Open an additional terminal session, then run the <code>prefect agent start</code> command, passing a <code>-q test</code> option that tells it to pull work from the <code>test</code> work pool. </p> <pre><code>$ prefect agent start -q test\nStarting agent connected to http://127.0.0.1:4200/api...\n\n  ___ ___ ___ ___ ___ ___ _____     _   ___ ___ _  _ _____\n | _ \\ _ \\ __| __| __/ __|_   _|   /_\\ / __| __| \\| |_   _|\n|  _/   / _|| _|| _| (__  | |    / _ \\ (_ | _|| .` | | |\n|_| |_|_\\___|_| |___\\___| |_|   /_/ \\_\\___|___|_|\\_| |_|\n\n\nAgent started! Looking for work from queue(s): test...\n</code></pre> <p>Remember that:</p> <ul> <li>We specified the <code>test</code> work pool when creating the deployment.</li> <li>The agent is configured to pick up work from the <code>test</code> work pool, so it will execute flow runs from the <code>log-flow/log-simple</code> deployment (and any others that also point at this queue).</li> </ul>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#run-the-deployment-locally","title":"Run the deployment locally","text":"<p>Now that you've created the deployment, agent, and associated work pool, you can interact with it in multiple ways. For example, you can use the Prefect CLI to run a local flow run for the deployment.</p> <pre><code>$ prefect deployment run log-flow/log-simple\nCreated flow run 'talented-jackdaw' (b0ba3195-912d-4a2f-8645-d939747655c3)\n</code></pre> <p>If you switch over to the terminal session where your agent is running, you'll see that the agent picked up the flow run and executed it.  Recall that we set an environment variable that configures the Prefect logging level for runs of this deployment.</p> <pre><code>12:34:34.000 | INFO    | prefect.agent - Submitting flow run '8476a5e7-cb8f-4fa0-911b-883ec289dccc'\n12:34:34.060 | INFO    | prefect.infrastructure.process - Opening process 'daffodil-vole'...\n12:34:34.068 | INFO    | prefect.agent - Completed submission of flow run '8476a5e7-cb8f-4fa0-911b-883ec289dccc'\n12:34:35.619 | DEBUG   | prefect.client - Connecting to API at http://127.0.0.1:4200/api/\n12:34:35.657 | DEBUG   | Flow run 'daffodil-vole' - Loading flow for deployment 'log-simple'...\n12:34:35.681 | DEBUG   | Flow run 'daffodil-vole' - Starting 'ConcurrentTaskRunner'; submitted tasks will be run concurrently...\n12:34:35.681 | DEBUG   | prefect.task_runner.concurrent - Starting task runner...\n12:34:35.688 | DEBUG   | prefect.client - Connecting to API at http://127.0.0.1:4200/api/\n12:34:35.797 | DEBUG   | Flow run 'daffodil-vole' - Executing flow 'log-flow' for flow run 'daffodil-vole'...\n12:34:35.797 | DEBUG   | Flow run 'daffodil-vole' - Beginning execution...\n12:34:35.821 | INFO    | Flow run 'daffodil-vole' - Created task run 'log_task-99465d2b-0' for task 'log_task'\n12:34:35.821 | INFO    | Flow run 'daffodil-vole' - Executing 'log_task-99465d2b-0' immediately...\n12:34:35.856 | DEBUG   | Task run 'log_task-99465d2b-0' - Beginning execution...\n12:34:35.857 | INFO    | Task run 'log_task-99465d2b-0' - Hello Marvin!\n12:34:35.857 | INFO    | Task run 'log_task-99465d2b-0' - Prefect Version = 2.3.1 \ud83d\ude80\n12:34:35.857 | DEBUG   | Task run 'log_task-99465d2b-0' - Hello from another file\n12:34:35.887 | INFO    | Task run 'log_task-99465d2b-0' - Finished in state Completed()\n12:34:35.914 | DEBUG   | prefect.task_runner.concurrent - Shutting down task runner...\n12:34:35.914 | INFO    | Flow run 'daffodil-vole' - Finished in state Completed('All states completed.')\n12:34:35.921 | DEBUG   | prefect.client - Connecting to API at http://127.0.0.1:4200/api/\n12:34:36.149 | INFO    | prefect.infrastructure.process - Process 'daffodil-vole' exited cleanly.\n</code></pre> <p>Note that we referenced the deployment by name in the format \"flow_name/deployment_name\". When you create new deployments in the future, remember that while a flow may be referenced by multiple deployments, each deployment must have a unique name.</p> <p>You can also see your flow in the Prefect UI. Open the Prefect UI at http://127.0.0.1:4200/. You'll see your deployment's flow run in the UI.</p> <p></p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#run-a-deployment-from-the-ui","title":"Run a deployment from the UI","text":"<p>With a work pool and agent in place, you can also create a flow run for <code>log_simple</code> directly from the UI.</p> <p>In the Prefect UI, select the Deployments page. You'll see a list of all deployments that have been created in this Prefect server instance.</p> <p></p> <p>Now select log-flow/log-simple to see details for the deployment you just created.</p> <p></p> <p>Select Parameters to see the default parameters you specified in the deployment definition.</p> <p></p> <p>You can start a flow run for this deployment from the UI by selecting the Run button, which gives you options to:</p> <ul> <li>Create a flow run with the default settings</li> <li>Create a flow run with custom settings</li> </ul> <p></p> <p>If you choose a Custom flow run, you can configure details including:</p> <ul> <li>Flow run name</li> <li>A description of the run</li> <li>Tags</li> <li>Scheduled start time</li> <li>Custom parameters</li> </ul> <p></p> <p>Let's change the <code>name</code> parameter for the next flow run. Under Parameters, select Custom.</p> <p>Change the value for the <code>name</code> parameter to some other value. We used \"Trillian\".</p> <p></p> <p>Select Save to save any changed values, then select Run to create the custom flow run.</p> <p>The Prefect orchestration engine routes the flow run request to the work pool, the agent picks up the new work from the pool and initiates the flow run. </p> <p>As before, the flow run will be picked up by the agent, and you should be able to see it run in the agent process.</p> <pre><code>12:37:50.045 | INFO    | prefect.agent - Submitting flow run '9ff2a05c-2dfd-4b27-a67b-b71fea06d12f'\n12:37:50.108 | INFO    | prefect.infrastructure.process - Opening process 'xi19-campor-g'...\n12:37:50.117 | INFO    | prefect.agent - Completed submission of flow run '9ff2a05c-2dfd-4b27-a67b-b71fea06d12f'\n12:37:52.241 | DEBUG   | prefect.client - Connecting to API at http://127.0.0.1:4200/api/\n12:37:52.281 | DEBUG   | Flow run 'xi19-campor-g' - Loading flow for deployment 'log-simple'...\n12:37:52.303 | DEBUG   | Flow run 'xi19-campor-g' - Starting 'ConcurrentTaskRunner'; submitted tasks will be run concurrently...\n12:37:52.304 | DEBUG   | prefect.task_runner.concurrent - Starting task runner...\n12:37:52.312 | DEBUG   | prefect.client - Connecting to API at http://127.0.0.1:4200/api/\n12:37:52.427 | DEBUG   | Flow run 'xi19-campor-g' - Executing flow 'log-flow' for flow run 'xi19-campor-g'...\n12:37:52.427 | DEBUG   | Flow run 'xi19-campor-g' - Beginning execution...\n12:37:52.456 | INFO    | Flow run 'xi19-campor-g' - Created task run 'log_task-99465d2b-0' for task 'log_task'\n12:37:52.456 | INFO    | Flow run 'xi19-campor-g' - Executing 'log_task-99465d2b-0' immediately...\n12:37:52.485 | DEBUG   | Task run 'log_task-99465d2b-0' - Beginning execution...\n12:37:52.486 | INFO    | Task run 'log_task-99465d2b-0' - Hello Trillian!\n12:37:52.487 | INFO    | Task run 'log_task-99465d2b-0' - Prefect Version = 2.3.1 \ud83d\ude80\n12:37:52.487 | DEBUG   | Task run 'log_task-99465d2b-0' - Hello from another file\n12:37:52.523 | INFO    | Task run 'log_task-99465d2b-0' - Finished in state Completed()\n12:37:52.551 | DEBUG   | prefect.task_runner.concurrent - Shutting down task runner...\n12:37:52.551 | INFO    | Flow run 'xi19-campor-g' - Finished in state Completed('All states completed.')\n12:37:52.558 | DEBUG   | prefect.client - Connecting to API at http://127.0.0.1:4200/api/\n12:37:52.792 | INFO    | prefect.infrastructure.process - Process 'xi19-campor-g' exited cleanly.\n</code></pre> <p>Go back the Flow Runs page in the UI and you'll see the flow run you just initiatied ran and was observed by the API.</p> <p></p> <p>Select the flow run to see details. In the flow run logs, you can see that the flow run logged a \"Hello Trillian!\" message as expected.</p> <p></p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#run-deployments-with-prefect-cloud","title":"Run deployments with Prefect Cloud","text":"<p>The steps in this tutorial also work to apply deployments to Prefect Cloud, which creates the corresponding flow runs.</p> <p>See the Prefect Cloud Quickstart for step-by-step instructions to log into Prefect Cloud, create a workspace, and configure your local environment to use Prefect Cloud as the API backend. Then run through this tutorial again, using Prefect Cloud instead of a local Prefect server.</p> <p>Already have a Prefect Cloud account? Logging in from your local development environment is as easy as <code>prefect cloud login</code>: </p> <pre><code>$ prefect cloud login\n? How would you like to authenticate? [Use arrows to move; enter to select]\n&gt; Log in with a web browser\nPaste an API key\nOpening browser...\nWaiting for response...\n? Which workspace would you like to use? [Use arrows to move; enter to select]\n&gt; prefect/terry-prefect-workspace\ng-gadflow/g-workspace\nAuthenticated with Prefect Cloud! Using workspace 'prefect/terry-prefect-workspace'.\n</code></pre> <p>Blocks and deployments are specific to a server or Prefect Cloud workspace</p> <p>Note that, if you ran through this tutorial on a local Prefect server instance, the storage and infrastructure blocks you created would not also be configured on Prefect Cloud. You must configure new storage and infrastructure blocks for any Prefect Cloud workspace.</p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#next-steps","title":"Next steps","text":"<p>So far you've seen a simple example of a single deployment for a single flow. But a common and useful pattern is to create multiple deployments for a flow. By using tags, parameters, and schedules effectively, you can have a single flow definition that serves multiple purposes or can be configured to run in different environments.</p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/deployments/#cleaning-up","title":"Cleaning up","text":"<p>You're welcome to leave the work pool and agent running to experiment and to handle local development.</p> <p>To terminate the agent, simply go to the terminal session where it's running and end the process with either <code>Ctrl+C</code> or by terminating the terminal session.</p> <p>You can pause or delete a work pool on the Prefect UI Work pools page.</p> <p>Next steps: Storage and infrastructure</p> <p>Deployments get interesting when you can execute flow runs in environments other than your local machine. To do that, you'll need to configure Storage and Infrastructure, which is covered in our next tutorial.    </p>","tags":["work pools","agents","orchestration","flow runs","deployments","schedules","tutorial"]},{"location":"tutorial/projects/","title":"Projects","text":"<p>refect projects are the recommended way to organize and manage Prefect deployments; projects provide a minimally opinionated, transparent way to organize your code and configuration so that its easy to debug.</p> <p>A project is a directory of code and configuration for your workflows that can be customized for portability.</p> <p>The main components of a project are 3 files:</p> <ul> <li><code>deployment.yaml</code>: a YAML file that can be used to specify settings for one or more flow deployments</li> <li><code>prefect.yaml</code>: a YAML file that contains procedural instructions for building artifacts for this project's deployments, pushing those artifacts, and retrieving them at runtime by a Prefect worker</li> <li><code>.prefect/</code>: a hidden directory that designates the root for your project; basic metadata about the workflows within this project are stored here</li> </ul> <p></p> <p>Projects require workers</p> <p>Note that using a project to manage your deployments requires the use of workers. This tutorial assumes that you have already set up two work pools, each with a worker, which only requires a single CLI command for each:</p> <ul> <li>Local: <code>prefect worker start -t process -p local-work</code></li> <li>Docker: <code>prefect worker start -t docker -p docker-work</code></li> </ul> <p>Each command will automatically create an appropriately typed work pool with default settings. For each type of worker you will need to install the specific worker from the collection repo.  For example, to start the Docker worker you will need to run <code>pip install prefect-docker</code>.  </p>","tags":["work pools","workers","orchestration","flow runs","deployments","projects","storage","infrastructure","blocks","tutorial","recipes"]},{"location":"tutorial/projects/#initializing-a-project","title":"Initializing a project","text":"<p>Initializing a project is simple: within any directory that you plan to develop flow code, run:</p> <pre><code>$ prefect project init\n</code></pre> <p>Note that you can safely run this command in a non-empty directory where you already have work, as well.</p> <p>This command will create your <code>.prefect/</code> directory along with the two YAML files <code>deployment.yaml</code> and <code>prefect.yaml</code>; if any of these files or directories already exist, they will not be altered or overwritten.</p> <p>Project Recipes</p> <p>Prefect ships with multiple project recipes, which allow you to initialize a project with a more opinionated structure suited to a particular use.  You can see all available recipes by running:</p> <p> <pre><code>$ prefect project recipe ls\n</code></pre> </p> <p>And you can use recipes with the <code>--recipe</code> flag:</p> <p> <pre><code>$ prefect project init --recipe docker\n</code></pre> </p> <p>Providing this flag will prompt you for required variables needed to make the recipe work properly.  If you want to run this CLI programmatically, these required fields can be provided via the <code>--field</code> flag: <code>prefect project init --recipe docker --field image_name=my-image/foo --field tag=dev</code>.</p> <p>If no recipe is provided, the <code>init</code> command makes an intelligent choice of recipe based on local configuration; for example, if you initialize a project within a git repository, Prefect will automatically use the <code>git</code> recipe.</p>","tags":["work pools","workers","orchestration","flow runs","deployments","projects","storage","infrastructure","blocks","tutorial","recipes"]},{"location":"tutorial/projects/#creating-a-basic-deployment","title":"Creating a basic deployment","text":"<p>Projects are most useful for creating deployments; let's walk through some examples.  </p>","tags":["work pools","workers","orchestration","flow runs","deployments","projects","storage","infrastructure","blocks","tutorial","recipes"]},{"location":"tutorial/projects/#local-deployment","title":"Local deployment","text":"<p>In this example, we'll create a project from scratch that runs locally.  Let's start by creating a new directory, making that our working directory, and initializing a project:</p> <pre><code>$ mkdir my-first-project\n$ cd my-first-project\n$ prefect project init --recipe local\n</code></pre> <p>Next, let's create a flow by saving the following code in a new file called <code>api_flow.py</code>:</p> <pre><code># contents of my-first-project/api_flow.py\n\nimport requests\nfrom prefect import flow\n\n\n@flow(name=\"Call API\", log_prints=True)\ndef call_api(url: str = \"http://time.jsontest.com/\"):\n\"\"\"Sends a GET request to the provided URL and returns the JSON response\"\"\"\n    resp = requests.get(url).json()\n    print(resp)\n    return resp\n</code></pre> <p>You can experiment by importing and running this flow in your favorite REPL; let's now elevate this flow to a deployment via the <code>prefect deploy</code> CLI command:</p> <pre><code>$ prefect deploy ./api_flow.py:call_api \\\n-n my-first-deployment \\\n-p local-work\n</code></pre> <p>This command will create a new deployment for your <code>\"Call API\"</code> flow with the name <code>\"my-first-deployment\"</code> that is attached to the <code>local-work</code> work pool.</p> <p>Note that Prefect has automatically done a few things for you:</p> <ul> <li>registered the existence of this flow with your local project</li> <li>created a description for this deployment based on the docstring of your flow function</li> <li>parsed the parameter schema for this flow function in order to expose an API for running this flow</li> </ul> <p>You can customize all of this either by manually editing <code>deployment.yaml</code> or by providing more flags to the <code>prefect deploy</code> CLI command; CLI inputs will be prioritized over hard-coded values in your deployment's YAML file when creating or updating a single deployment.</p> <p>Let's create two ad-hoc runs for this deployment and confirm things are healthy:</p> <pre><code>$ prefect deployment run 'Call API/my-first-deployment'\n$ prefect deployment run 'Call API/my-first-deployment' \\\n--param url=https://cat-fact.herokuapp.com/facts/\n</code></pre> <p>You should now be able to monitor and confirm these runs were created and ran in the UI.</p> <p>Flow registration</p> <p><code>prefect deploy</code> will automatically register your flow with your local project; you can register flows yourself explicitly with the <code>prefect project register-flow</code> command:  <pre><code>$ prefect project register-flow ./api_flow.py:call_api\n</code></pre> </p> <p>This pre-registration allows you to deploy based on name instead of entrypoint path:  <pre><code>$ prefect deploy -f 'Call API' \\\n-n my-first-deployment \\\n-p local-work\n</code></pre> </p>","tags":["work pools","workers","orchestration","flow runs","deployments","projects","storage","infrastructure","blocks","tutorial","recipes"]},{"location":"tutorial/projects/#git-based-deployment","title":"Git-based deployment","text":"<p>In this example, we'll initialize a project from a pre-built GitHub repository and see how it is automatically portable across machines.</p> <p>We start by cloning the remote repository and initializing a project within the root of the repo directory:</p> <pre><code>$ git clone https://github.com/PrefectHQ/hello-projects\n$ cd hello-projects\n$ prefect project init --recipe git\n</code></pre> <p>We can now proceed with the same steps as above to create a new deployment:</p> <pre><code>$ prefect deploy -f 'log-flow' \\\n-n my-git-deployment \\\n-p local-work\n</code></pre> <p>Notice that we were able to deploy based on flow name alone; this is because the repository owner pre-registered the <code>log-flow</code> for us.  Alternatively, if we knew the full entrypoint path, we could run <code>prefect deploy ./flows/log_flow.py:log_flow</code>.</p> <p>Let's run this flow and discuss it's output:</p> <pre><code>$ prefect deployment run 'log-flow/my-git-deployment'\n</code></pre> <p>In your worker process, you should see output that looks something like this:</p> <pre><code>Cloning into 'hello-projects'...\n...\n12:01:43.188 | INFO    | Task run 'log_task-0' - Hello Marvin!\n12:01:43.189 | INFO    | Task run 'log_task-0' - Prefect Version = 2.8.7+84.ge479b48b6.dirty \ud83d\ude80\n12:01:43.189 | INFO    | Task run 'log_task-0' - Hello from another file\n...\n12:01:43.236 | INFO    | Task run 'log_config-0' - Found config {'some-piece-of-config': 100}\n...\n12:01:43.266 | INFO    | Flow run 'delicate-labrador' - Finished in state Completed('All states completed.')\n</code></pre> <p>A few important notes on what we're looking at here:</p> <ul> <li>You'll notice the message \"Hello from another file\"; this flow imports code from other related files within the project. Prefect takes care of migrating the entire project directory for you, which includes files that you may import from</li> <li>Similarly, the configuration that is logged is located within the root directory of this project; you can always consider this root directory your working directory both locally and when this deployment is executed remotely</li> <li>Lastly, note the top line \"Cloning into 'hello-projects'...\"; because this project is based out of a GitHub repository, it is automatically portable to any remote location where both <code>git</code> and <code>prefect</code> are configured! You can convince yourself of this by either running a new local worker on a different machine, or by switching this deployment to run with your docker work pool (more on this shortly).</li> </ul> <p><code>prefect.yaml</code></p> <p>The above process worked out-of-the-box because of the information stored within <code>prefect.yaml</code>; if you open this file up in a text editor, you'll find that is not empty.  Specifically, it contains the following <code>pull</code> step that was automatically populated when you first ran <code>prefect project init</code>: <pre><code>pull:\n- prefect.projects.steps.git_clone_project:\nrepository: https://github.com/PrefectHQ/hello-projects.git\nbranch: main\naccess_token: null\n</code></pre> If pulling from a private repository, your pull step might appear like below.  Note that the access_token is a \"Secret\" type, which will be retrieved and inferred. <pre><code>pull:\n- prefect.projects.steps.git_clone_project:\nrepository: https://github.com/PrivateRepo/test-private-repo.git\nbranch: main\naccess_token: \"{{ prefect.blocks.secret.my-github-secret }}\"\n</code></pre> These <code>pull</code> steps are the instructions sent to your worker's runtime environment that allow it to clone your project in remote locations. For more information, see the project concept documentation.</p> <p>For more examples of configuration options available for cloning projects, see the <code>git_clone_project</code> step documentation.</p>","tags":["work pools","workers","orchestration","flow runs","deployments","projects","storage","infrastructure","blocks","tutorial","recipes"]},{"location":"tutorial/projects/#dockerized-deployment","title":"Dockerized deployment","text":"<p>In this example, we extend the examples above by dockerizing our setup and executing runs with a Docker Worker.  Building off the git-based example above, let's switch our deployment to submit work to the <code>docker-work</code> work pool that we started at the beginning:</p> <pre><code>$ prefect deploy -f 'log-flow' \\\n-n my-docker-git-deployment \\\n-p docker-work\n$ prefect deployment run 'log-flow/my-docker-git-deployment'\n</code></pre> <p>As promised above, this worked out of the box!  </p> <p>Let's deploy a new flow from this project that requires additional dependencies that might not be available in the default image our work pool is using; this flow requires both <code>pandas</code> and <code>numpy</code> as a dependency, which we will install locally first to confirm the flow is working:</p> <pre><code>$ pip install -r requirements.txt\n$ python flows/pandas_flow.py\n</code></pre> <p>We now have two options for how to manage these dependencies in our worker's environment:</p> <ul> <li>setting the <code>EXTRA_PIP_PACKAGES</code> environment variable or using another hook to install the dependencies at runtime</li> <li>building a custom Docker image with the dependencies baked in</li> </ul> <p>In this tutorial, we will focus on building a custom Docker image. First, we need to configure a <code>build</code> step within our <code>prefect.yaml</code> file as follows (Note: if starting from scratch we could use the <code>docker-git</code> recipe):</p> <pre><code># partial contents of prefect.yaml\n\nbuild:\n- prefect_docker.projects.steps.build_docker_image:\nimage_name: local-only/testing\ntag: dev\ndockerfile: auto\npush: false\n\npull:\n- prefect.projects.steps.git_clone_project:\nrepository: https://github.com/PrefectHQ/hello-projects.git\nbranch: main\naccess_token: null\n</code></pre> <p>A few notes:</p> <ul> <li>each step references a function with inputs and outputs</li> <li>in this case, we are using <code>dockerfile: auto</code> to tell Prefect to automatically create a <code>Dockerfile</code> for us; otherwise we could write our own and pass its location as a path to the <code>dockerfile</code> kwarg</li> <li>to avoid dealing with real image registries, we are not pushing this image; in most use cases you will want <code>push: true</code> (which is the default)</li> <li>to see all available configuration options for building Docker images, see the <code>build_docker_image</code> step documentation</li> </ul> <p>All that's left to do is create our deployment and specify our image name to instruct the worker what image to pull:</p> <pre><code>$ prefect deploy -f 'pandas-flow' \\\n-n docker-build-deployment \\\n-p docker-work \\\n-v image=local-only/testing:dev\n$ prefect deployment run 'log-flow/my-docker-git-deployment'\n</code></pre> <p>Your run should complete successfully, logs and all!  Note that the <code>-v</code> flag represents a job variable, which are the allowed pieces of infrastructure configuration on a given work pool.  Each work pool can customize the fields they accept here.</p> <p>Templating values</p> <p>As a matter of best practice, you should avoid hardcoding the image name and tag in both your <code>prefect.yaml</code> and CLI. Instead, you should use variable templating.</p>","tags":["work pools","workers","orchestration","flow runs","deployments","projects","storage","infrastructure","blocks","tutorial","recipes"]},{"location":"tutorial/projects/#dockerizing-a-local-deployment","title":"Dockerizing a local deployment","text":"<p>Revisiting our local deployment above, let's begin by switching it to submit work to our <code>docker-work</code> work pool by re-running <code>prefect deploy</code> to see what happens:</p> <pre><code>$ prefect deploy ./api_flow.py:call_api \\\n-n my-second-deployment \\\n-p docker-work\n$ prefect deployment run 'Call API/my-second-deployment'\n</code></pre> <p>This fails with the following error:</p> <pre><code>ERROR: FileNotFoundError: [Errno 2] No such file or directory: '/Users/chris/dev/my-first-project'\n</code></pre> <p>The reason this occurs is because our deployment has a fundamentally local <code>pull</code> step; inspecting <code>prefect.yaml</code> we find:</p> <pre><code>pull:\n- prefect.projects.steps.set_working_directory:\ndirectory: /Users/chris/dev/my-first-project\n</code></pre> <p>In order to successfully submit such a project to a dockerized environment, we need to either:</p> <ul> <li><code>push</code> this project to a remote location (such as a Cloud storage bucket)</li> <li><code>build</code> this project into a Docker image artifact </li> </ul> <p>Advanced: <code>push</code> steps</p> <p>Populating a <code>push</code> step is considered an advanced feature of projects that requires additional considerations to ensure the <code>pull</code> step is compatible with the <code>push</code> step; as such it is out of scope for this tutorial.</p> <p>Following the same structure as above, we will include a new <code>build</code> step as well as alter our <code>pull</code> step to be compatible with the built image's filesystem:</p> <pre><code># partial contents of prefect.yaml\n\nbuild:\n- prefect_docker.projects.steps.build_docker_image:\nimage_name: local-only/testing\ntag: dev2\ndockerfile: auto\npush: false\n\npull:\n- prefect.projects.steps.set_working_directory:\ndirectory: /opt/prefect/hello-projects\n</code></pre> <p>Rerunning the same <code>deploy</code> command above now makes this a healthy deployment!</p>","tags":["work pools","workers","orchestration","flow runs","deployments","projects","storage","infrastructure","blocks","tutorial","recipes"]},{"location":"tutorial/projects/#customizing-the-steps","title":"Customizing the steps","text":"<p>For more information on what can be customized with <code>prefect.yaml</code>, check out the Projects concept doc.</p>","tags":["work pools","workers","orchestration","flow runs","deployments","projects","storage","infrastructure","blocks","tutorial","recipes"]}]}